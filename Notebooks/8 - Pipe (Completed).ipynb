{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8eb727d-da5f-4e71-b80b-70f2ecf503f6",
   "metadata": {},
   "source": [
    "#### PIPE - 8:    \n",
    "This pipe covers the following : \n",
    "1. All features of pipe 7\n",
    "3. Integration of processing blur.\n",
    "4. Improved tracker shape and efficiency\n",
    "5. Integration of Phase 3 for ANRP (Final Phase)\n",
    "6. Integration of JSON for tracking all the violations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0638f4fb-e66f-425d-8af7-c7dae4453d8b",
   "metadata": {},
   "source": [
    "NOTE : We will be also defining the final strucut of json need for capturing violation in the following file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e68932-d9ff-4b93-a667-6480b05bd295",
   "metadata": {},
   "source": [
    "Order of entried in json\n",
    "\n",
    "violation_type_id - ADDED    \n",
    "vehicle_type_id - ADDED    \n",
    "vehicle_speed - ADDED    \n",
    "travel_direction - ADDED    \n",
    "location_id - ADDED    \n",
    "camera_id - ADDED    \n",
    "evidence_image_url - ADDED    \n",
    "numbe_plate_ocr_image_url  - ADDED     \n",
    "evidence_video_url   - ADDED     \n",
    "numbe_plate_image_url - ADDED    \n",
    "scanned_number_plate_number - ADDED         \n",
    "violation_date   - ADDED    \n",
    "violation_time   - ADDED    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c4805b-d999-4453-930b-ad1faa9ddfce",
   "metadata": {},
   "source": [
    "##### Strucutre of JSON\n",
    "main_json={\n",
    "\"tracking_id\":{ and the rest entries}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7234e7bb-a0af-4b21-bcd3-54ad4b4f9e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "import threading \n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "from boxmot import StrongSORT\n",
    "from utils.utils import *\n",
    "\n",
    "\n",
    "ssd=[\n",
    "     {'id': 3, 'name': 'car', 'vehicle_class': 'lmv'},\n",
    "     {'id': 4, 'name': 'motorcycle', 'vehicle_class': 'mcwg/mcg'},\n",
    "     {'id': 5, 'name': 'truck', 'vehicle_class': 'hgmv'},\n",
    "     {'id': 6, 'name': 'bus', 'vehicle_class': 'hpmv'},\n",
    "     {'id': 7, 'name': 'rikshaw', 'vehicle_class': 'l5m'}\n",
    "    ]\n",
    "voi=[\n",
    "   {'id': 2, 'name': 'over_speed'}, \n",
    "   {'id': 3, 'name': 'no_helmet'}\n",
    "]\n",
    "vehicle_class_json=violation_based_json_creator(ssd)\n",
    "violation_type_json=violation_based_json_creator(voi)\n",
    "down = {}\n",
    "up = {}\n",
    "text_color = (0, 0, 0)  # Black color for text\n",
    "yellow_color = (0, 255, 255)  # Yellow color for background\n",
    "red_color = (0, 0, 255)  # Red color for lines\n",
    "blue_color = (255, 0, 0)  # Blue color for lines\n",
    "\n",
    "\n",
    "counter_down = []\n",
    "counter_up = []\n",
    "\n",
    "first_boundry_y=170\n",
    "\n",
    "red_line_y = 198\n",
    "\n",
    "blue_line_y = 280\n",
    "\n",
    "offset = 6\n",
    "# Specify the start and end points of the line\n",
    "start_point = (300, 198)\n",
    "end_point = (300, 280)\n",
    "\n",
    "all_id_tracker=[]\n",
    "voilation_id_tracker=[]\n",
    "violation_frame_tracker={}\n",
    "\n",
    "main_violation_tracker_json={}\n",
    "x_start=300\n",
    "x_end=800\n",
    "y_start=198\n",
    "y_end=280\n",
    "#This inputs will be directly taken from front_end\n",
    "location_id=-1\n",
    "camera_id=-1\n",
    "frame_count=0\n",
    "video_path='/media/hlink/hd/test_videos/testx_vid_1.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb54272f-e0f9-41f3-be55-5992fb11b72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-27 13:33:25.956\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mboxmot.appearance.reid_model_factory\u001b[0m:\u001b[36mload_pretrained_weights\u001b[0m:\u001b[36m207\u001b[0m - \u001b[32m\u001b[1mSuccessfully loaded pretrained weights from \"models/osnet_x0_25_msmt17.pt\"\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 3 speed is -> 38\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 4 speed is -> 44\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 38 speed is -> 34\n",
      "for 35 speed is -> 26\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 48 speed is -> 31\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 57 speed is -> 33\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 60 speed is -> 25\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 71 speed is -> 39\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 74 speed is -> 29\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 92 speed is -> 24\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 94 speed is -> 43\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 99 speed is -> 43\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 110 speed is -> 25\n",
      "for 111 speed is -> 22\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 120 speed is -> 25\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 133 speed is -> 48\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 139 speed is -> 21\n",
      "adding Id to tracker\n",
      "for 127 speed is -> 29\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 140 speed is -> 33\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 153 speed is -> 45\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 156 speed is -> 55\n",
      "adding Id to tracker\n",
      "for 157 speed is -> 32\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 166 speed is -> 34\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 173 speed is -> 10\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 177 speed is -> 57\n",
      "for 175 speed is -> 39\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 180 speed is -> 52\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 196 speed is -> 37\n",
      "adding Id to tracker\n",
      "for 202 speed is -> 49\n",
      "for 200 speed is -> 35\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 216 speed is -> 44\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 228 speed is -> 43\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 233 speed is -> 33\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 257 speed is -> 30\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 260 speed is -> 30\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 266 speed is -> 20\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 280 speed is -> 38\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 299 speed is -> 29\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 307 speed is -> 31\n",
      "adding Id to tracker\n",
      "for 308 speed is -> 30\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 335 speed is -> 40\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 340 speed is -> 24\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 364 speed is -> 32\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 363 speed is -> 49\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 366 speed is -> 24\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 375 speed is -> 41\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 381 speed is -> 45\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 406 speed is -> 37\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 407 speed is -> 30\n",
      "for 410 speed is -> 22\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 411 speed is -> 40\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 433 speed is -> 36\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 448 speed is -> 29\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 449 speed is -> 35\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 463 speed is -> 24\n",
      "for 464 speed is -> 28\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 469 speed is -> 31\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 475 speed is -> 33\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 479 speed is -> 41\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 483 speed is -> 27\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 502 speed is -> 20\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 513 speed is -> 34\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 520 speed is -> 33\n",
      "adding Id to tracker\n",
      "for 528 speed is -> 26\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 545 speed is -> 38\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 556 speed is -> 24\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "for 557 speed is -> 27\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "adding Id to tracker\n",
      "total_time 948.3897051811218\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "tracker=tracker_init(cuda_device=torch.cuda.is_available(),cuda_device_number=1)\n",
    "model=YOLO('models/yolov8l.pt')\n",
    "yolo_model_classes=model.names\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out_main = cv2.VideoWriter('output_strongs.avi', fourcc, 20.0, (1020, 500))\n",
    "all_frames_record_path=create_directory('all_frames_record')\n",
    "violation_frames_record_path=create_directory('all_violation_record')\n",
    "current_date=get_current_date()\n",
    "\n",
    "while True:    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    resized_image=cv2.resize(frame,(1020, 500))\n",
    "    blurred_image=blur_except_rectangle(resized_image,x_start,y_start,x_end,y_end,offset_size=[30,80],blur_kernel_size=(15,15))\n",
    "    \n",
    "    results=model.predict(blurred_image,conf=0.4,verbose=False,device=[0],classes=[2,3])\n",
    "    # print(f\"\\n----------------------------------------------------------------------------------\\nResult without detection \\n{results[0].boxes.data}\\n----------------------------------------------------------------------------------\\n\")\n",
    "    blurred_image=line_plotter(frame=blurred_image,x_start=300,x_end=774,y=198,line_color=red_color,line_name='boundry 1',line_thickness=2,text_color=text_color)\n",
    "    blurred_image=line_plotter(frame=blurred_image,x_start=300,x_end=800,y=280,line_color=blue_color,line_name='boundry 2',line_thickness=2,text_color=text_color)\n",
    "    \n",
    "    # Specify the color of the line in BGR format (here, it's white)\n",
    "    color = (255, 255, 255)\n",
    "    \n",
    "    # Draw the vertical line on the image\n",
    "    thickness = 2  # You can adjust the thickness as needed\n",
    "    cv2.line(blurred_image, start_point, end_point, color, thickness)\n",
    "    \n",
    "    # im=cv2.rectangle(blurred_image, (300, 198), (800, 280), (255, 255, 255), 2)\n",
    "    \n",
    "    px,conf=prediction_coordinated_hadler(results)\n",
    "    dets = []\n",
    "    # Experimenting\n",
    "    dets,object_class_id=tracker_element_handler(dets,px,conf)        \n",
    "    \n",
    "    # print('out_from')\n",
    "    \n",
    "    dets = np.array(dets)\n",
    "    # print(dets)\n",
    "    if len(dets) > 0:\n",
    "        tracks = tracker.update(dets, blurred_image) # --> M X (x, y, x, y, id, conf, cls, ind)\n",
    "        # print('tracks',tracks)    \n",
    "        for track in tracks:\n",
    "                travel_direction=-1\n",
    "                \n",
    "                blurred_image,object_id,cx,cy,bbox_list,conf=plot_tracks(track,blurred_image)\n",
    "                if f'{object_id}' in main_violation_tracker_json:\n",
    "                    pass\n",
    "                else:\n",
    "                    main_violation_tracker_json[f'{object_id}']={}\n",
    "                    # print(\"adding Id to tracker\")\n",
    "                all_id_tracker.append(object_id)\n",
    "                \n",
    "                # Adding file path for csv\n",
    "                csv_file_path=detection_coordinate_write(frame_count,object_id,bbox_list,'all_frame_detection_detail.csv')\n",
    "            \n",
    "                if red_line_y<(cy+offset) and red_line_y > (cy-offset):\n",
    "                    # print(\"entered if 1\")\n",
    "                    down[object_id]=time.time()\n",
    "            \n",
    "                if object_id in down:\n",
    "                    # print(\"entered if 2\")\n",
    "               \n",
    "                    if blue_line_y<(cy+offset) and blue_line_y > (cy-offset):\n",
    "                         # print(\"entered if 3\")\n",
    "                         travel_direction=1\n",
    "                         elapsed_time=time.time() - down[object_id] \n",
    "                         # print(\"entered if 4\")\n",
    "                         if counter_down.count(object_id)==0:\n",
    "                            counter_down.append(object_id) \n",
    "                            distance = 9\n",
    "                            est_speed=speed_calculator_kmph(distance,elapsed_time)\n",
    "                            if est_speed>20:\n",
    "                                \n",
    "                                # Fucntion for timer tracking\n",
    "                                \n",
    "                                time_dict=video_time_checker(count=frame_count,cap=cap)\n",
    "                                \n",
    "                                # Getting the name for the detected object\n",
    "                                object_name=object_class_name_normalizer(object_class_id,yolo_model_classes)\n",
    "                                \n",
    "                                                              \n",
    "                                main_violation_tracker_json[f'{object_id}']['violation_type_id']=violation_type_json['over_speed']\n",
    "                                main_violation_tracker_json[f'{object_id}']['vehicle_type_id']=vehicle_class_json[f'{object_name}']\n",
    "                                \n",
    "                                main_violation_tracker_json[f'{object_id}']['vehicle_speed']=est_speed\n",
    "                                main_violation_tracker_json[f'{object_id}']['travel_direction']=travel_direction\n",
    "\n",
    "                                main_violation_tracker_json[f'{object_id}']['location_id']=location_id\n",
    "                                main_violation_tracker_json[f'{object_id}']['camera_id']=camera_id\n",
    "\n",
    "                                main_violation_tracker_json[f'{object_id}']['violation_date']=current_date\n",
    "                                main_violation_tracker_json[f'{object_id}']['violation_time']=time_dict['time']\n",
    "                                \n",
    "                                voilation_id_tracker.append(object_id)\n",
    "                                violation_frame_tracker[object_id]=frame_count\n",
    "                                # violation_frame_writer_op=frame_writer(frame_count,im,violation_frames_record_path)\n",
    "                                # print(\"bbox_list-\",bbox_list)\n",
    "                                object_class_id\n",
    "                                violation_frame_writer_original=frame_writer(frame_count,resized_image,violation_frames_record_path)\n",
    "                                violation_frame_writer_blurred=frame_writer(frame_count,resized_image,violation_frames_record_path,coordiante_blur=True,bbox_list=bbox_list)\n",
    "                                \n",
    "                                main_violation_tracker_json[f'{object_id}']['evidence_focused_image_url']=violation_frame_writer_blurred\n",
    "                                main_violation_tracker_json[f'{object_id}']['evidence_image_url']=violation_frame_writer_original\n",
    "                                            \n",
    "                                violation_csv_file_path=detection_coordinate_write(frame_count,object_id,bbox_list,'violation_frame_detection_detail.csv')\n",
    "                                \n",
    "                            # print(f\"for {object_id} speed is -> {est_speed}\")\n",
    "    \n",
    "    all_frame_writer_op=frame_writer(frame_count,resized_image,all_frames_record_path)    \n",
    "    frame_count+=1\n",
    "    out_main.write(resized_image)\n",
    "    \n",
    "    # # break on pressing q or spaceq\n",
    "    cv2.imshow('Strong Sort Detection detection', blurred_image)     \n",
    "    # key = cv2.waitKey(25) & 0xFF\n",
    "    \n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "remove_model_from_gpu(model)\n",
    "end_time=time.time()\n",
    "print(f'total_time {end_time-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33967600-cdb2-45ff-b24f-f34efa3acf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "order_maintainer - True\n",
      "CPU times: user 1min 39s, sys: 36.5 s, total: 2min 15s\n",
      "Wall time: 25.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "main_violation_json=voilation_capture_json_creator(voilation_id_tracker,csv_file_path)\n",
    "maintained=json_frame_order_checker(main_violation_json)\n",
    "if maintained:\n",
    "    # Function for creating dir paths only\n",
    "    evidance_img_dir_paths,evidance_clip_dir_paths=evidance_directories_creator(main_violation_json)\n",
    "    # Function for taking separating image\n",
    "    evidance_img_dir_paths=evidance_img_separator(evidance_img_dir_paths,all_frames_record_path,main_violation_json)\n",
    "    \n",
    "    video_clip_creator_mt(voilation_id_tracker,violation_frame_tracker,evidance_clip_dir_paths,all_frames_record_path,main_violation_tracker_json)\n",
    "    cropped_images_path_list=evidance_cropper_mt(evidance_img_dir_paths,main_violation_json)\n",
    "    deblurred_image_paths=deblur_images(cropped_images_path_list,main_violation_json)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffab123f-09e7-46c3-aa7c-5c3d6eb5b885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting thread with id : 0\n",
      "starting thread with id : 1\n",
      "CPU times: user 6.04 s, sys: 1.2 s, total: 7.24 s\n",
      "Wall time: 20min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Using default 8 threads to achive max effiencicy\n",
    "enhance_image_path=image_enhancement_using_limit_mpx(deblurred_image_paths,num_threads=8)\n",
    "cropped_lp_paths=preprocssing_part_one(enhance_image_path,'models/LPD.pt',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c7b3960-8991-4ad5-912a-abdf15a94a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 517 ms, sys: 1.04 s, total: 1.56 s\n",
      "Wall time: 24min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "enhanced_cropped_images_lp=image_enhancement_using_limit_mpx(cropped_lp_paths,num_threads=8,dir_name='cropped_lp_enhanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f172c1b4-82c5-4656-a8c8-c98b8e66a31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/74',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/57',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/139',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/60',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/92',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/364',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/479',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/483',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/464',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/469',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/475',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/366',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/381',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/406',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/407',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/410',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/299',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/307',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/308',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/335',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/340',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/257',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/260',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/280',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/3',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/110',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/111',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/120',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/153',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/127',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/196',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/133',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/513',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/520',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/528',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/545',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/556',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/99',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/4',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/38',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/35',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/48',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/411',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/433',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/448',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/449',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/463',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/202',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/166',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/180',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/94',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/140',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/557',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/71',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/175',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/156',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/157',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/363',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/375',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/177',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/200',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/216',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/228',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/enhanced_images_cropped_lp_enhanced/233']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_cropped_images_lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a11fcd49-adf1-4f8d-8ec1-5fd29ce9f088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.54 ms, sys: 366 ms, total: 373 ms\n",
      "Wall time: 768 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "thresholded_image=create_threshold_imgs_mp(enhanced_cropped_images_lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36ce02c0-76ca-4cbb-a65b-ae081194e443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/74',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/57',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/139',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/60',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/92',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/364',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/479',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/483',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/464',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/469',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/475',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/366',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/381',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/406',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/407',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/410',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/299',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/307',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/308',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/335',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/340',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/257',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/260',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/280',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/3',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/110',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/111',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/120',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/153',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/127',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/513',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/520',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/528',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/545',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/556',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/99',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/196',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/4',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/38',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/35',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/48',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/133',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/166',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/411',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/433',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/448',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/449',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/463',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/202',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/157',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/363',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/375',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/180',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/94',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/140',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/557',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/71',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/175',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/156',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/177',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/200',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/216',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/228',\n",
       " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/233']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "376cecd0-d156-472e-9a81-339e75488f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57a202b3-7457-491b-92ad-0aa36fdf5277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_sub_process_phase_three(folder_paths,csv_file_name,tr_model,tr_processor,tr_device):\n",
    "        for path in folder_paths:\n",
    "            path=str(path)\n",
    "            # print(type(path))\n",
    "            file_list=sort_files_by_name(path)\n",
    "            idx=path.split('/')[-1]\n",
    "            \n",
    "            for image_path in file_list:\n",
    "                \n",
    "                img = cv2.imread(image_path)\n",
    "                #Currently we write each and every possiblity in the csv file for each Possible ID\n",
    "                strings=run_ocr(img,tr_model,tr_device,tr_processor)\n",
    "                final_string=compare_strings(strings)\n",
    "                \n",
    "                if valid_license_plate(final_string): \n",
    "                    final_csv_string=f'{idx},{final_string},{image_path}'\n",
    "\n",
    "                else:\n",
    "                    final_csv_string=f'{idx},{\"\"},{image_path}'\n",
    "\n",
    "                file_writer(final_csv_string,csv_file_name)\n",
    "\n",
    "def ocr_processor_mp_phase_three(folder_paths,num_thread=3):\n",
    "        all_process_list=[]\n",
    "        chunks=list_divider(folder_paths,number_of_part=num_thread)    \n",
    "        tr_ocr_models=tr_ocr_model_loader(numthreads=num_thread)\n",
    "        # main_queue=multiprocessing.Queue()\n",
    "        current_date=get_current_date()\n",
    "        csv_file_name=f\"{current_date}_ocr_results.csv\"\n",
    "        csv_file_path=os.path.join(os.getcwd(),csv_file_name)\n",
    "        for chunk,model_json in zip(chunks,tr_ocr_models):\n",
    "            print(chunk)\n",
    "            t=threading.Thread(target=ocr_sub_process_phase_three,args=[chunk,csv_file_name,model_json['model'],model_json['processor'],model_json['device']])\n",
    "            t.start()\n",
    "            all_process_list.append(t)\n",
    "        for process in all_process_list:\n",
    "            process.join()\n",
    "        return csv_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24094c08-c80e-4a8d-84e0-9f284ee562a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-small-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-small-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-small-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/74' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/57' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/139'\n",
      " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/60' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/92' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/364'\n",
      " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/479' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/483' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/464'\n",
      " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/469' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/475' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/366'\n",
      " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/381' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/406' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/407'\n",
      " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/410' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/299' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/307'\n",
      " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/308' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/335' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/340'\n",
      " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/257']\n",
      "<class 'str'>\n",
      "['/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/260' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/280' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/3'\n",
      " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/110' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/111' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/120'\n",
      " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/153' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/127' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/513'\n",
      " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/520' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/528' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/545'\n",
      " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/556' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/99' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/196'\n",
      " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/4' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/38' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/35'\n",
      " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/48' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/133' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/166']\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/411' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/433' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/448'\n",
      " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/449' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/463' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/202'\n",
      " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/157' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/363' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/375'\n",
      " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/180' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/94' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/140'\n",
      " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/557' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/71' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/175'\n",
      " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/156' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/177' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/200'\n",
      " '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/216' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/228' '/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/233']\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/hlink/workspace/learning/boxmot/bmt/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 33s, sys: 13 s, total: 1min 46s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lp_csv_path=ocr_processor_mp_phase_three(folder_paths=thresholded_image,num_thread=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68b577c4-8461-4b66-84c3-8db1b7d177eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lp_csv_path='/home/hlink/workspace/learning/boxmot/27_05_2024_ocr_results.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2a2a8c0-8406-42e2-ad4a-f161d68e7b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path='/home/hlink/workspace/learning/boxmot/24_05_2024_ocr_results.csv'\n",
    "ocr_json=ocr_result_filter(main_violation_tracker_json,lp_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f062e415-5ee9-41d3-8588-e2fa28fb5b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_violation_tracker_json=final_json_processor(main_violation_tracker_json,ocr_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "808eb8e9-0455-4385-9e90-89225551a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_violation_tracker_json=remove_empty_from_dict(main_violation_tracker_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c478caed-7750-436d-87ee-0e33ebadc675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ba04b4-eca4-47b2-b010-c66a239d5895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_result_filter(main_violation_tracker_json,csv_file_path):\n",
    "    main_json={}\n",
    "    with open(csv_file_path,'r') as file:\n",
    "        contents=file.readlines()\n",
    "        # print(contents)\n",
    "    splitted_file_contetns=[content.split(',') for content in contents ]\n",
    "    # print(type(splitted_file_contetns[0][0]))\n",
    "    for idx in main_violation_tracker_json:\n",
    "            temp_list=[]\n",
    "            for count,entry in enumerate(splitted_file_contetns):\n",
    "                if str(idx)==str(entry[0]):\n",
    "                    temp_list.append(splitted_file_contetns[count])\n",
    "            if temp_list:\n",
    "                main_json[f'{idx}']=temp_list\n",
    "    return main_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf545e-07ef-44a5-8ab2-192b90527a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_json_processor(main_violation_tracker_json,violation_json):\n",
    "    \n",
    "    current_dir=os.getcwd()\n",
    "    fall_back_lp=os.path.join(current_dir,'system_fall_back_assets','fall_back_normal_lp.png')\n",
    "    fall_back_lp_scanned=os.path.join(current_dir,'system_fall_back_assets','fall_back_scanned_lp.png')\n",
    "    fall_back_number_plate_number='MH40BP4321'\n",
    "    str_to_rep='threashold_lp_images'\n",
    "    scanned_liscense_plate_path=''\n",
    "    for i in main_violation_tracker_json:\n",
    "        strings=[]\n",
    "        if main_violation_tracker_json[i]:    \n",
    "            main_violation_tracker_json[i]['numbe_plate_ocr_image_url']=fall_back_lp_scanned\n",
    "            main_violation_tracker_json[i]['numbe_plate_image_url']=fall_back_lp\n",
    "            main_violation_tracker_json[i]['scanned_number_plate_number']=fall_back_number_plate_number\n",
    "            if i in violation_json:\n",
    "                for j in violation_json[i]:\n",
    "                    if j[1]!='':\n",
    "                       scanned_liscense_plate_path=j[-1]\n",
    "                       strings.append(j[1])\n",
    "                if len(strings)>0:    \n",
    "                    result=compare_strings(strings)\n",
    "                    main_violation_tracker_json[i]['numbe_plate_ocr_image_url']=scanned_liscense_plate_path\n",
    "                    main_violation_tracker_json[i]['numbe_plate_image_url']=scanned_liscense_plate_path.replace(str_to_rep,'enhanced_images_cropped_lp_enhanced').replace('\\n','')\n",
    "                    main_violation_tracker_json[i]['scanned_number_plate_number']=result \n",
    "            \n",
    "    return main_violation_tracker_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c135439-05ff-4567-a4bf-3d02689a62a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo='/home/hlink/workspace/learning/boxmot/27_05_2024_infenrence_output/threashold_lp_images/375/10765.jpg\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd7c1e6-7f9f-4b3e-a692-80167452ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_to_rep='threashold_lp_images'\n",
    "replaced=demo.replace(str_to_rep,'enhanced_images_cropped_lp_enhanced').replace('\\n','')\n",
    "print(replaced)\n",
    "print(os.path.exists(replaced))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmt",
   "language": "python",
   "name": "bmt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
